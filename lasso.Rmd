---
title: "beta coefficients plot"
author: "Yanelli Nunez"
date: "7/12/2019"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---


-If I give you seed 3 I get a full range and if I give you seed 1 I get a single point. 
-Do group lasso with single element groupings and see if we can replicate lasso
-what is the vector matrix structure that we suppose to use for grp lasso 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(caret)
library(Hmisc)
library(glmnet)
#library(grpreg)
```

Note: R is version: 3.6.1
glmnet and grpreg package are the new versions
```{r}
sessionInfo()
```

### Data Import and Cleaning 

First, load the dataset; clean up names as needed; and convert factors to, well, factors. Next we remove missing values and reorder predictors (environmental variables first, confounders second). In keeping with standard practice, we'll ln-transform the environmental exposures and the outcome. This is the dataset we'll use to illustrate variable selection methods.

```{r}
study_pop = read_csv("Data/studypop.csv") %>% 
  clean_names(case = c("old_janitor")) %>% 
  mutate(bmi_cat3 = as.factor(bmi_cat3),
         edu_cat = as.factor(edu_cat),
         race_cat = as.factor(race_cat),
         male = as.factor(male)) 

data = study_pop %>% 
  mutate_at(vars(contains("la")), log) %>% 
  mutate(log_telomean = log(telomean)) %>% 
  dplyr::select(log_telomean, lbx074la:lbx187la, lbxd03la:lbx194la, everything(), -seqn, -telomean) %>% 
  na.omit(log_telomean) 

# Create a matrix of predictors as x
x = model.matrix(log_telomean ~ ., data)[,-1]

# Extract outcome vector
y = data$log_telomean
```

# Lasso 
### Lasso w/ CV

Some built-in functions will conduct a cross-validation analysis and identify the "best" tuning parameter.
Optional arguments to `glmnet` can be useful -- in particular, `weights` can be used in the context of the adaptive lasso and `penalty.factor` can separate penalized variables from confounders. 

```{r}
set.seed(2)

is_penalized = c(rep(1, ncol(x[,1:18])), rep(0, ncol(x[,19:36])))

# Use cross-validation (CV) to find best lambda value
cv.lasso = cv.glmnet(x, y, 
                     penalty.factor = is_penalized,
                     type.measure = "mse", alpha = 1)
plot(cv.lasso)

best_lambda = cv.lasso$lambda.min
best_lambda
```


### Looping seeds for lasso for coefficients plot
```{r}
fit_cv_lasso = function(seed) {
  set.seed(seed)
  cv.lasso = cv.glmnet(x, y, 
                     penalty.factor = c(rep(1, ncol(x[,1:18])), rep(0, ncol(x[,19:36]))),
                     type.measure = "mse", alpha = 1)
  
  #Find the lambda that results in the smallest CV error
  best_lambda <- cv.lasso$lambda.min
 
  
  #Fit model with cross-validated lambda
  lasso.mod = glmnet(x, y, 
                   penalty.factor = c(rep(1, ncol(x[,1:18])), rep(0, ncol(x[,19:36]))),
                   alpha = 1, lambda = best_lambda)

lasso.mod
}


extract_coefs = function(fit) {
 as.tibble(as.matrix(fit$beta), rownames = "variable") %>%
    rename(beta = s0) 
}


repeat_cv_lasso = 
  tibble(seed = 1:100) %>% 
  mutate(
    fits = map(seed, ~fit_cv_lasso(seed = .x)),
    coefs = map(fits, extract_coefs)) %>% 
  dplyr::select(-fits) %>% 
  unnest() %>%
  rename(beta_lasso = "beta") 


```

### Looping seeds for lasso for lambda plot
```{r}

fit_cv_lasso_2 = function(seed) {
  set.seed(seed)
  cv.lasso = cv.glmnet(x, y, 
                     penalty.factor = c(rep(1, ncol(x[,1:18])), rep(0, ncol(x[,19:36]))),
                     type.measure = "mse", alpha = 1)

  
 loop_cvm    <- cv.lasso$cvm  # mean cross-validation error
  loop_cvsd   <- cv.lasso$cvsd #std error of CV error
  loop_lam    <- cv.lasso$lambda 
  
  dat <- cbind(lam = loop_lam, cvm = loop_cvm, cvsd = loop_cvsd) %>% 
    as_tibble() %>% 
    mutate(upper = cvm + 1.96*cvsd,
         lower = cvm - 1.96*cvsd) %>% 
    mutate(seed1 = seed)

}

repeat_cv_lasso_2 = 
  tibble(seed = 1:100) %>%
  mutate(
    fits = map(seed, ~fit_cv_lasso_2(seed = .x))) %>% 
  unnest() %>% 
  mutate(seed = as.factor(seed))

  
```


# Lasso visualization

#### betas
```{r}
repeat_cv_lasso  %>%
  ggplot() + 
  geom_point(aes(x = seed, y = beta_lasso), color = 'red', size = 0.5, alpha = 0.5) + 
  facet_wrap(~variable) + 
  geom_hline(yintercept = 0) +
  ggtitle("1000 observations")

```


### Lambda with Error Bars
```{r}
repeat_cv_lasso_2 %>% 
  ggplot(aes(x = lam, y = cvm, color = seed)) + 
  geom_point() + 
  geom_line() +
  geom_errorbar(aes(ymin = lower, ymax = upper)) +
  theme(legend.position = "none") +
  labs(x = expression(lambda), y = "Cross-Validation Error")
```


### Lambda without Error Bars
```{r}
repeat_cv_lasso_2 %>% 
  ggplot(aes(x = lam, y = cvm, color = seed)) + 
  geom_point() + 
  geom_line() +
  theme(legend.position = "none") +
  labs(x = expression(lambda), y = "Cross-Validation Error")
```


### Selected lambda
```{r}
min_cv <- repeat_cv_lasso_2 %>% 
  group_by(seed) %>% 
  filter(cvm == min(cvm))

min_cv %>% 
  ggplot(aes(y = lam, x = seed)) + 
  geom_point(aes(color = lam)) + 
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90, size = 7)) +
  labs(x = "seed", y = expression("Cross-Validation Selected "*lambda))
```


# Group lasso

Variable grouping for group lasso

```{r}
group3 <- vector()
group3[grepl("lbx1|0",colnames(x))] <- "Non-Dioxin-like PCB"
group3[grepl("lbxd", colnames(x))] <- "TEQ"
group3[grepl("lbxf", colnames(x))] <- "TEQ"
group3[grepl("lbxh|p", colnames(x))] <- "Non-Ortho PCB"
group3[grepl("lbx118la", colnames(x))] <- "TEQ"
group3[grepl("pct", colnames(x))] <- "0"
group3[grepl("bcsi", colnames(x))] <- "0"
group3[grepl("bmi", colnames(x))] <- "0"
group3[grepl("edu", colnames(x))] <- "0"
group3[grepl("race", colnames(x))] <- "0"
group3[grepl("male", colnames(x))] <- "0"
group3[grepl("bxcot", colnames(x))] <- "0"
group3[grepl("age", colnames(x))] <- "0"
group3 <- as.factor(group3)

cbind(colnames(x), group3) #bind by columns


```


This doesn't work when we have the right grouping 
```{r}
cv_lasso_3 <- cv.grpreg(x, y, group3, 
                        penalty = "grLasso", seed = 1988,
                        n.lambda = 200, max.iter = 20000)

plot(cv_lasso_3)
```


### Looping for different seeds for group lasso
```{r}
fit_with_cv = function(seed) {
  cv_lasso_3 <- cv.grpreg(x, y, group3, 
                          penalty = "grLasso", seed = seed,
                          n.lambda = 200, max.iter = 20000)
  
  #Find the lambda that results in the smallest CV error
  best_lasso_3 <- cv_lasso_3$lambda.min
  
  #Fit model with cross-validated lambda
  fit_lasso_3 <- grpreg(x, y, group3, penalty = "grLasso", lambda = best_lasso_3)
  
  fit_lasso_3
}

extract_coefs_grlasso = function(fit) {
  as_tibble(fit$beta, rownames = "variable") %>% 
    rename(beta = 2) %>% 
    filter(variable != "(Intercept)")  %>% 
    mutate(group3 = group3) %>% 
    filter(group3 %in% c("TEQ", "Non-Dioxin-like PCB", "Non-Ortho PCB"))
}

repeat_cv_group_lasso = 
  tibble(seed = 1:100) %>% 
  mutate(
    fits = map(seed, ~fit_with_cv(seed = .x)),
    coefs = map(fits, extract_coefs_grlasso)) %>% 
  dplyr::select(-fits) %>% 
  unnest() %>%
  rename(beta_grlasso = "beta")
  

```


combined data sets for plotting
```{r}
#betas <- full_join(repeat_cv_elnet, repeat_cv_lasso, by = c("variable", "seed")) %>%
 # full_join(., repeat_cv_group_lasso, by = c("variable", "seed")) 
          
```
                            
Combined plot 
```{r}
#betas_plot <- betas %>%
 # ggplot() + 
  #geom_point(aes(x = seed, y = beta_lasso, color = 'red'), size = 0.5, alpha = 0.7) + 
  #geom_point(aes(x = seed, y = beta_elnet, color = 'blue'), size = 0.5, alpha = 0.4) +
  #geom_point(aes(x = seed, y = beta_grlasso, color = 'dark green'), size = 0.5, alpha = 0.5) +
  #facet_wrap(~variable) +
  #ggtitle("Beta values for different seeds") +
  #labs(y = "beta") +
  #scale_colour_manual(name = "", 
   #     values =c('blue'='blue','red'='red', 'dark green' = 'dark green'), labels = c('Elastic Net','Lasso', 'group Lasso'))
#betas_plot
```


### beta plot for group lasso
```{r}
#inconsistend coefficients when looping the seed
repeat_cv_group_lasso %>%
  ggplot() + 
  geom_point(aes(x = seed, y = beta_grlasso), color = 'dark green', size = 0.5, alpha = 0.5) + 
  facet_wrap(~variable) +
  geom_hline(yintercept = 0)

```


